<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>knn.html</title>
  <meta name="generator" content="Haroopad 0.13.1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>div.oembedall-githubrepos{border:1px solid #DDD;border-radius:4px;list-style-type:none;margin:0 0 10px;padding:8px 10px 0;font:13.34px/1.4 helvetica,arial,freesans,clean,sans-serif;width:452px;background-color:#fff}div.oembedall-githubrepos .oembedall-body{background:-moz-linear-gradient(center top,#FAFAFA,#EFEFEF);background:-webkit-gradient(linear,left top,left bottom,from(#FAFAFA),to(#EFEFEF));border-bottom-left-radius:4px;border-bottom-right-radius:4px;border-top:1px solid #EEE;margin-left:-10px;margin-top:8px;padding:5px 10px;width:100%}div.oembedall-githubrepos h3{font-size:14px;margin:0;padding-left:18px;white-space:nowrap}div.oembedall-githubrepos p.oembedall-description{color:#444;font-size:12px;margin:0 0 3px}div.oembedall-githubrepos p.oembedall-updated-at{color:#888;font-size:11px;margin:0}div.oembedall-githubrepos ul.oembedall-repo-stats{border:none;float:right;font-size:11px;font-weight:700;padding-left:15px;position:relative;z-index:5;margin:0}div.oembedall-githubrepos ul.oembedall-repo-stats li{border:none;color:#666;display:inline-block;list-style-type:none;margin:0!important}div.oembedall-githubrepos ul.oembedall-repo-stats li a{background-color:transparent;border:none;color:#666!important;background-position:5px -2px;background-repeat:no-repeat;border-left:1px solid #DDD;display:inline-block;height:21px;line-height:21px;padding:0 5px 0 23px}div.oembedall-githubrepos ul.oembedall-repo-stats li:first-child a{border-left:medium none;margin-right:-3px}div.oembedall-githubrepos ul.oembedall-repo-stats li a:hover{background:5px -27px no-repeat #4183C4;color:#FFF!important;text-decoration:none}div.oembedall-githubrepos ul.oembedall-repo-stats li:first-child a:hover{border-bottom-left-radius:3px;border-top-left-radius:3px}ul.oembedall-repo-stats li:last-child a:hover{border-bottom-right-radius:3px;border-top-right-radius:3px}span.oembedall-closehide{background-color:#aaa;border-radius:2px;cursor:pointer;margin-right:3px}div.oembedall-container{margin-top:5px;text-align:left}.oembedall-ljuser{font-weight:700}.oembedall-ljuser img{vertical-align:bottom;border:0;padding-right:1px}.oembedall-stoqembed{border-bottom:1px dotted #999;float:left;overflow:hidden;width:730px;line-height:1;background:#FFF;color:#000;font-family:Arial,Liberation Sans,DejaVu Sans,sans-serif;font-size:80%;text-align:left;margin:0;padding:0}.oembedall-stoqembed a{color:#07C;text-decoration:none;margin:0;padding:0}.oembedall-stoqembed a:hover{text-decoration:underline}.oembedall-stoqembed a:visited{color:#4A6B82}.oembedall-stoqembed h3{font-family:Trebuchet MS,Liberation Sans,DejaVu Sans,sans-serif;font-size:130%;font-weight:700;margin:0;padding:0}.oembedall-stoqembed .oembedall-reputation-score{color:#444;font-size:120%;font-weight:700;margin-right:2px}.oembedall-stoqembed .oembedall-user-info{height:35px;width:185px}.oembedall-stoqembed .oembedall-user-info .oembedall-user-gravatar32{float:left;height:32px;width:32px}.oembedall-stoqembed .oembedall-user-info .oembedall-user-details{float:left;margin-left:5px;overflow:hidden;white-space:nowrap;width:145px}.oembedall-stoqembed .oembedall-question-hyperlink{font-weight:700}.oembedall-stoqembed .oembedall-stats{background:#EEE;margin:0 0 0 7px;padding:4px 7px 6px;width:58px}.oembedall-stoqembed .oembedall-statscontainer{float:left;margin-right:8px;width:86px}.oembedall-stoqembed .oembedall-votes{color:#555;padding:0 0 7px;text-align:center}.oembedall-stoqembed .oembedall-vote-count-post{font-size:240%;color:#808185;display:block;font-weight:700}.oembedall-stoqembed .oembedall-views{color:#999;padding-top:4px;text-align:center}.oembedall-stoqembed .oembedall-status{margin-top:-3px;padding:4px 0;text-align:center;background:#75845C;color:#FFF}.oembedall-stoqembed .oembedall-status strong{color:#FFF;display:block;font-size:140%}.oembedall-stoqembed .oembedall-summary{float:left;width:635px}.oembedall-stoqembed .oembedall-excerpt{line-height:1.2;margin:0;padding:0 0 5px}.oembedall-stoqembed .oembedall-tags{float:left;line-height:18px}.oembedall-stoqembed .oembedall-tags a:hover{text-decoration:none}.oembedall-stoqembed .oembedall-post-tag{background-color:#E0EAF1;border-bottom:1px solid #3E6D8E;border-right:1px solid #7F9FB6;color:#3E6D8E;font-size:90%;line-height:2.4;margin:2px 2px 2px 0;padding:3px 4px;text-decoration:none;white-space:nowrap}.oembedall-stoqembed .oembedall-post-tag:hover{background-color:#3E6D8E;border-bottom:1px solid #37607D;border-right:1px solid #37607D;color:#E0EAF1}.oembedall-stoqembed .oembedall-fr{float:right}.oembedall-stoqembed .oembedall-statsarrow{background-image:url(http://cdn.sstatic.net/stackoverflow/img/sprites.png?v=3);background-repeat:no-repeat;overflow:hidden;background-position:0 -435px;float:right;height:13px;margin-top:12px;width:7px}.oembedall-facebook1{border:1px solid #1A3C6C;padding:0;font:13.34px/1.4 verdana;width:500px}.oembedall-facebook2{background-color:#627add}.oembedall-facebook2 a{color:#e8e8e8;text-decoration:none}.oembedall-facebookBody{background-color:#fff;vertical-align:top;padding:5px}.oembedall-facebookBody .contents{display:inline-block;width:100%}.oembedall-facebookBody div img{float:left;margin-right:5px}div.oembedall-lanyard{-webkit-box-shadow:none;-webkit-transition-delay:0s;-webkit-transition-duration:.4000000059604645s;-webkit-transition-property:width;-webkit-transition-timing-function:cubic-bezier(0.42,0,.58,1);background-attachment:scroll;background-clip:border-box;background-color:transparent;background-image:none;background-origin:padding-box;border-width:0;box-shadow:none;color:#112644;display:block;float:left;font-family:'Trebuchet MS',Trebuchet,sans-serif;font-size:16px;height:253px;line-height:19px;margin:0;max-width:none;min-height:0;outline:#112644 0;overflow-x:visible;overflow-y:visible;padding:0;position:relative;text-align:left;vertical-align:baseline;width:804px}div.oembedall-lanyard .tagline{font-size:1.5em}div.oembedall-lanyard .wrapper{overflow:hidden;clear:both}div.oembedall-lanyard .split{float:left;display:inline}div.oembedall-lanyard .prominent-place .flag:active,div.oembedall-lanyard .prominent-place .flag:focus,div.oembedall-lanyard .prominent-place .flag:hover,div.oembedall-lanyard .prominent-place .flag:link,div.oembedall-lanyard .prominent-place .flag:visited{float:left;display:block;width:48px;height:48px;position:relative;top:-5px;margin-right:10px}div.oembedall-lanyard .place-context{font-size:.889em}div.oembedall-lanyard .prominent-place .sub-place{display:block}div.oembedall-lanyard .prominent-place{font-size:1.125em;line-height:1.1em;font-weight:400}div.oembedall-lanyard .main-date{color:#8CB4E0;font-weight:700;line-height:1.1}div.oembedall-lanyard .first{width:48.57%;margin:0 0 0 2.857%}.mermaid .label{color:#333}.node circle,.node polygon,.node rect{fill:#cde498;stroke:#13540c;stroke-width:1px}.edgePath .path{stroke:green;stroke-width:1.5px}.cluster rect{fill:#cdffb2;rx:40;stroke:#6eaa49;stroke-width:1px}.cluster text{fill:#333}.actor{stroke:#13540c;fill:#cde498}text.actor{fill:#000;stroke:none}.actor-line{stroke:grey}.messageLine0{stroke-width:1.5;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#333}.messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#arrowhead{fill:#333}#crosshead path{fill:#333!important;stroke:#333!important}.messageText{fill:#333;stroke:none}.labelBox{stroke:#326932;fill:#cde498}.labelText,.loopText{fill:#000;stroke:none}.loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#326932}.note{stroke:#6eaa49;fill:#fff5ad}.noteText{fill:#000;stroke:none;font-family:'trebuchet ms',verdana,arial;font-size:14px}.section{stroke:none;opacity:.2}.section0,.section2{fill:#6eaa49}.section1,.section3{fill:#fff;opacity:.2}.sectionTitle0,.sectionTitle1,.sectionTitle2,.sectionTitle3{fill:#333}.sectionTitle{text-anchor:start;font-size:11px;text-height:14px}.grid .tick{stroke:lightgrey;opacity:.3;shape-rendering:crispEdges}.grid path{stroke-width:0}.today{fill:none;stroke:red;stroke-width:2px}.task{stroke-width:2}.taskText{text-anchor:middle;font-size:11px}.taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}.taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}.taskText0,.taskText1,.taskText2,.taskText3{fill:#fff}.task0,.task1,.task2,.task3{fill:#487e3a;stroke:#13540c}.taskTextOutside0,.taskTextOutside1,.taskTextOutside2,.taskTextOutside3{fill:#000}.active0,.active1,.active2,.active3{fill:#cde498;stroke:#13540c}.activeText0,.activeText1,.activeText2,.activeText3{fill:#000!important}.done0,.done1,.done2,.done3{stroke:grey;fill:lightgrey;stroke-width:2}.doneText0,.doneText1,.doneText2,.doneText3{fill:#000!important}.crit0,.crit1,.crit2,.crit3{stroke:#f88;fill:red;stroke-width:2}.activeCrit0,.activeCrit1,.activeCrit2,.activeCrit3{stroke:#f88;fill:#cde498;stroke-width:2}.doneCrit0,.doneCrit1,.doneCrit2,.doneCrit3{stroke:#f88;fill:lightgrey;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}.activeCritText0,.activeCritText1,.activeCritText2,.activeCritText3,.doneCritText0,.doneCritText1,.doneCritText2,.doneCritText3{fill:#000!important}.titleText{text-anchor:middle;font-size:18px;fill:#000}text{font-family:'trebuchet ms',verdana,arial;font-size:14px}html{height:100%}body{margin:0!important;padding:5px 20px 26px!important;background-color:#fff;font-family:"Lucida Grande","Segoe UI","Apple SD Gothic Neo","Malgun Gothic","Lucida Sans Unicode",Helvetica,Arial,sans-serif;font-size:.9em;overflow-x:hidden;overflow-y:auto}br,h1,h2,h3,h4,h5,h6{clear:both}hr.page{background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x;border:0;height:3px;padding:0}hr.underscore{border-top-style:dashed!important}body >:first-child{margin-top:0!important}img.plugin{box-shadow:0 1px 3px rgba(0,0,0,.1);border-radius:3px}iframe{border:0}figure{-webkit-margin-before:0;-webkit-margin-after:0;-webkit-margin-start:0;-webkit-margin-end:0}kbd{border:1px solid #aaa;-moz-border-radius:2px;-webkit-border-radius:2px;border-radius:2px;-moz-box-shadow:1px 2px 2px #ddd;-webkit-box-shadow:1px 2px 2px #ddd;box-shadow:1px 2px 2px #ddd;background-color:#f9f9f9;background-image:-moz-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:-o-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:-webkit-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:linear-gradient(top,#eee,#f9f9f9,#eee);padding:1px 3px;font-family:inherit;font-size:.85em}.oembeded .oembed_photo{display:inline-block}img[data-echo]{margin:25px 0;width:100px;height:100px;background:url(../img/ajax.gif) center center no-repeat #fff}.spinner{display:inline-block;width:10px;height:10px;margin-bottom:-.1em;border:2px solid rgba(0,0,0,.5);border-top-color:transparent;border-radius:100%;-webkit-animation:spin 1s infinite linear;animation:spin 1s infinite linear}.spinner:after{content:'';display:block;width:0;height:0;position:absolute;top:-6px;left:0;border:4px solid transparent;border-bottom-color:rgba(0,0,0,.5);-webkit-transform:rotate(45deg);transform:rotate(45deg)}@-webkit-keyframes spin{to{-webkit-transform:rotate(360deg)}}@keyframes spin{to{transform:rotate(360deg)}}p.toc{margin:0!important}p.toc ul{padding-left:10px}p.toc>ul{padding:10px;margin:0 10px;display:inline-block;border:1px solid #ededed;border-radius:5px}p.toc li,p.toc ul{list-style-type:none}p.toc li{width:100%;padding:0;overflow:hidden}p.toc li a::after{content:"."}p.toc li a:before{content:"• "}p.toc h5{text-transform:uppercase}p.toc .title{float:left;padding-right:3px}p.toc .number{margin:0;float:right;padding-left:3px;background:#fff;display:none}input.task-list-item{margin-left:-1.62em}.markdown{font-family:"Hiragino Sans GB","Microsoft YaHei",STHeiti,SimSun,"Lucida Grande","Lucida Sans Unicode","Lucida Sans",'Segoe UI',AppleSDGothicNeo-Medium,'Malgun Gothic',Verdana,Tahoma,sans-serif;padding:20px}.markdown a{text-decoration:none;vertical-align:baseline}.markdown a:hover{text-decoration:underline}.markdown h1{font-size:2.2em;font-weight:700;margin:1.5em 0 1em}.markdown h2{font-size:1.8em;font-weight:700;margin:1.275em 0 .85em}.markdown h3{font-size:1.6em;font-weight:700;margin:1.125em 0 .75em}.markdown h4{font-size:1.4em;font-weight:700;margin:.99em 0 .66em}.markdown h5{font-size:1.2em;font-weight:700;margin:.855em 0 .57em}.markdown h6{font-size:1em;font-weight:700;margin:.75em 0 .5em}.markdown h1+p,.markdown h1:first-child,.markdown h2+p,.markdown h2:first-child,.markdown h3+p,.markdown h3:first-child,.markdown h4+p,.markdown h4:first-child,.markdown h5+p,.markdown h5:first-child,.markdown h6+p,.markdown h6:first-child{margin-top:0}.markdown hr{border:1px solid #ccc}.markdown p{margin:1em 0;word-wrap:break-word}.markdown ol{list-style-type:decimal}.markdown li{display:list-item;line-height:1.4em}.markdown blockquote{margin:1em 20px}.markdown blockquote>:first-child{margin-top:0}.markdown blockquote>:last-child{margin-bottom:0}.markdown blockquote cite:before{content:'\2014 \00A0'}.markdown .code{border-radius:3px;word-wrap:break-word}.markdown pre{border-radius:3px;word-wrap:break-word;border:1px solid #ccc;overflow:auto;padding:.5em}.markdown pre code{border:0;display:block}.markdown pre>code{font-family:Consolas,Inconsolata,Courier,monospace;font-weight:700;white-space:pre;margin:0}.markdown code{border-radius:3px;word-wrap:break-word;border:1px solid #ccc;padding:0 5px;margin:0 2px}.markdown img{max-width:100%}.markdown mark{color:#000;background-color:#fcf8e3}.markdown table{padding:0;border-collapse:collapse;border-spacing:0;margin-bottom:16px}.markdown table tr td,.markdown table tr th{border:1px solid #ccc;margin:0;padding:6px 13px}.markdown table tr th{font-weight:700}.markdown table tr th>:first-child{margin-top:0}.markdown table tr th>:last-child{margin-bottom:0}.markdown table tr td>:first-child{margin-top:0}.markdown table tr td>:last-child{margin-bottom:0}@import url(http://fonts.googleapis.com/css?family=Roboto+Condensed:300italic,400italic,700italic,400,300,700);.haroopad{padding:20px;color:#222;font-size:15px;font-family:"Roboto Condensed",Tauri,"Hiragino Sans GB","Microsoft YaHei",STHeiti,SimSun,"Lucida Grande","Lucida Sans Unicode","Lucida Sans",'Segoe UI',AppleSDGothicNeo-Medium,'Malgun Gothic',Verdana,Tahoma,sans-serif;background:#fff;line-height:1.6;-webkit-font-smoothing:antialiased}.haroopad a{color:#3269a0}.haroopad a:hover{color:#4183c4}.haroopad h2{border-bottom:1px solid #e6e6e6}.haroopad h6{color:#777}.haroopad hr{border:1px solid #e6e6e6}.haroopad blockquote>code,.haroopad h1>code,.haroopad h2>code,.haroopad h3>code,.haroopad h4>code,.haroopad h5>code,.haroopad h6>code,.haroopad li>code,.haroopad p>code,.haroopad td>code{font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;font-size:85%;background-color:rgba(0,0,0,.02);padding:.2em .5em;border:1px solid #efefef}.haroopad pre>code{font-size:1em;letter-spacing:-1px;font-weight:700}.haroopad blockquote{border-left:4px solid #e6e6e6;padding:0 15px;color:#777}.haroopad table{background-color:#fafafa}.haroopad table tr td,.haroopad table tr th{border:1px solid #e6e6e6}.haroopad table tr:nth-child(2n){background-color:#f2f2f2}.hljs{display:block;overflow-x:auto;padding:.5em;background:#fdf6e3;color:#657b83;-webkit-text-size-adjust:none}.diff .hljs-header,.hljs-comment,.hljs-doctype,.hljs-javadoc,.hljs-pi,.lisp .hljs-string{color:#93a1a1}.css .hljs-tag,.hljs-addition,.hljs-keyword,.hljs-request,.hljs-status,.hljs-winutils,.method,.nginx .hljs-title{color:#859900}.hljs-command,.hljs-dartdoc,.hljs-hexcolor,.hljs-link_url,.hljs-number,.hljs-phpdoc,.hljs-regexp,.hljs-rules .hljs-value,.hljs-string,.hljs-tag .hljs-value,.tex .hljs-formula{color:#2aa198}.css .hljs-function,.hljs-built_in,.hljs-chunk,.hljs-decorator,.hljs-id,.hljs-identifier,.hljs-localvars,.hljs-title,.vhdl .hljs-literal{color:#268bd2}.hljs-attribute,.hljs-class .hljs-title,.hljs-constant,.hljs-link_reference,.hljs-parent,.hljs-type,.hljs-variable,.lisp .hljs-body,.smalltalk .hljs-number{color:#b58900}.css .hljs-pseudo,.diff .hljs-change,.hljs-attr_selector,.hljs-cdata,.hljs-header,.hljs-pragma,.hljs-preprocessor,.hljs-preprocessor .hljs-keyword,.hljs-shebang,.hljs-special,.hljs-subst,.hljs-symbol,.hljs-symbol .hljs-string{color:#cb4b16}.hljs-deletion,.hljs-important{color:#dc322f}.hljs-link_label{color:#6c71c4}.tex .hljs-formula{background:#eee8d5}.MathJax_Hover_Frame{border-radius:.25em;-webkit-border-radius:.25em;-moz-border-radius:.25em;-khtml-border-radius:.25em;box-shadow:0 0 15px #83A;-webkit-box-shadow:0 0 15px #83A;-moz-box-shadow:0 0 15px #83A;-khtml-box-shadow:0 0 15px #83A;border:1px solid #A6D!important;display:inline-block;position:absolute}.MathJax_Hover_Arrow{position:absolute;width:15px;height:11px;cursor:pointer}#MathJax_About{position:fixed;left:50%;width:auto;text-align:center;border:3px outset;padding:1em 2em;background-color:#DDD;color:#000;cursor:default;font-family:message-box;font-size:120%;font-style:normal;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;z-index:201;border-radius:15px;-webkit-border-radius:15px;-moz-border-radius:15px;-khtml-border-radius:15px;box-shadow:0 10px 20px gray;-webkit-box-shadow:0 10px 20px gray;-moz-box-shadow:0 10px 20px gray;-khtml-box-shadow:0 10px 20px gray;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}.MathJax_Menu{position:absolute;background-color:#fff;color:#000;width:auto;padding:5px 0;border:1px solid #CCC;margin:0;cursor:default;font:menu;text-align:left;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;z-index:201;border-radius:5px;-webkit-border-radius:5px;-moz-border-radius:5px;-khtml-border-radius:5px;box-shadow:0 10px 20px gray;-webkit-box-shadow:0 10px 20px gray;-moz-box-shadow:0 10px 20px gray;-khtml-box-shadow:0 10px 20px gray;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}.MathJax_MenuItem{padding:1px 2em;background:0 0}.MathJax_MenuArrow{position:absolute;right:.5em;color:#666}.MathJax_MenuActive .MathJax_MenuArrow{color:#fff}.MathJax_MenuArrow.RTL{left:.5em;right:auto}.MathJax_MenuCheck{position:absolute;left:.7em}.MathJax_MenuCheck.RTL{right:.7em;left:auto}.MathJax_MenuRadioCheck{position:absolute;left:.7em}.MathJax_MenuRadioCheck.RTL{right:.7em;left:auto}.MathJax_MenuLabel{padding:1px 2em 3px 1.33em;font-style:italic}.MathJax_MenuRule{border-top:1px solid #DDD;margin:4px 3px}.MathJax_MenuDisabled{color:GrayText}.MathJax_MenuActive{background-color:#606872;color:#fff}.MathJax_Menu_Close{position:absolute;width:31px;height:31px;top:-15px;left:-15px}#MathJax_Zoom{position:absolute;background-color:#F0F0F0;overflow:auto;display:block;z-index:301;padding:.5em;border:1px solid #000;margin:0;font-weight:400;font-style:normal;text-align:left;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;box-shadow:5px 5px 15px #AAA;-webkit-box-shadow:5px 5px 15px #AAA;-moz-box-shadow:5px 5px 15px #AAA;-khtml-box-shadow:5px 5px 15px #AAA;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}#MathJax_ZoomOverlay{position:absolute;left:0;top:0;z-index:300;display:inline-block;width:100%;height:100%;border:0;padding:0;margin:0;background-color:#fff;opacity:0;filter:alpha(opacity=0)}#MathJax_ZoomFrame{position:relative;display:inline-block;height:0;width:0}#MathJax_ZoomEventTrap{position:absolute;left:0;top:0;z-index:302;display:inline-block;border:0;padding:0;margin:0;background-color:#fff;opacity:0;filter:alpha(opacity=0)}.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1px;bottom:2px;background-color:#E6E6E6;border:1px solid #959595;margin:0;padding:2px 8px;z-index:102;color:#000;font-size:80%;width:auto;white-space:nowrap}#MathJax_MSIE_Frame{position:absolute;top:0;left:0;width:0;z-index:101;border:0;margin:0;padding:0}.MathJax_Error{color:#C00;font-style:italic}footer{position:fixed;font-size:.8em;text-align:right;bottom:0;margin-left:-25px;height:20px;width:100%}</style>
</head>
<body class="markdown haroopad">
<h1 id="k-nearest-neighbor-(knn)-exercise"><a name="k-nearest-neighbor-(knn)-exercise" href="#k-nearest-neighbor-(knn)-exercise"></a>k-Nearest Neighbor (kNN) exercise</h1><p>Complete and run <em>Run_knn.m</em> in this exercise.You could run this script section by section. For more details see the assignments page on the course website.</p><p>The kNN classifier consists of two stages:</p><ul>
<li>During training, the classifier takes the training data and simply remembers it</li><li>During testing, kNN classifies every test image by comparing to all training images and transfering the labels of the k most similar training examples</li><li>The value of k is cross-validated</li></ul><p>In this exercise you will implement these steps and understand the basic Image Classification pipeline, cross-validation, and gain proficiency in writing efficient, vectorized code.</p><h4 id="section-1:-load-database-and-check-its-dimensions"><a name="section-1:-load-database-and-check-its-dimensions" href="#section-1:-load-database-and-check-its-dimensions"></a>section 1: Load database and check its dimensions</h4><pre><code data-origin="<pre><code>%% Load the raw CIFAR-10 data.
imdb = load_datasets();

% As a sanity check, we print out the size of the training and test data.
disp('Training data shape: ');
disp(size(imdb.train_data));
disp('Training labels shape: ');
disp(size(imdb.train_labels));
disp('Test data shape: ');
disp(size(imdb.test_data));
disp('Test labels shape: ');
disp(size(imdb.test_labels));
</code></pre>">%% Load the raw CIFAR-10 data.
imdb = load_datasets();

% As a sanity check, we print out the size of the training and test data.
disp('Training data shape: ');
disp(size(imdb.train_data));
disp('Training labels shape: ');
disp(size(imdb.train_labels));
disp('Test data shape: ');
disp(size(imdb.test_data));
disp('Test labels shape: ');
disp(size(imdb.test_labels));
</code></pre><h4 id="section-2:-visualize-some-examples-from-the-dataset"><a name="section-2:-visualize-some-examples-from-the-dataset" href="#section-2:-visualize-some-examples-from-the-dataset"></a>section 2: Visualize some examples from the dataset</h4><pre><code data-origin="<pre><code>%We show a few examples of training images from each class.
show_datasets(imdb);
</code></pre>">%We show a few examples of training images from each class.
show_datasets(imdb);
</code></pre><p><strong>The expected results</strong>:<br><img src="https://raw.githubusercontent.com/MatthiasDING/BE_1/master/Document/dataset.jpg" alt=""></p><h4 id="section-3:-subsample-the-dataset-and-reshape-the-data"><a name="section-3:-subsample-the-dataset-and-reshape-the-data" href="#section-3:-subsample-the-dataset-and-reshape-the-data"></a>section 3: Subsample the dataset and reshape the data</h4><pre><code data-origin="<pre><code>%% Subsample the data for more efficient code execution in this exercise
imdb = subsample_datasets(imdb);

%% Reshape the image data into rows
imdb.train_data = reshape(imdb.train_data, size(imdb.train_data,1), []);
imdb.test_data = reshape(imdb.test_data, size(imdb.test_data,1), []);

disp('Training data shape: ');
disp(size(imdb.train_data));
disp('Training labels shape: ');
disp(size(imdb.train_labels));
disp('Test data shape: ');
disp(size(imdb.test_data));
disp('Test labels shape: ');
disp(size(imdb.test_labels));
</code></pre>">%% Subsample the data for more efficient code execution in this exercise
imdb = subsample_datasets(imdb);

%% Reshape the image data into rows
imdb.train_data = reshape(imdb.train_data, size(imdb.train_data,1), []);
imdb.test_data = reshape(imdb.test_data, size(imdb.test_data,1), []);

disp('Training data shape: ');
disp(size(imdb.train_data));
disp('Training labels shape: ');
disp(size(imdb.train_labels));
disp('Test data shape: ');
disp(size(imdb.test_data));
disp('Test labels shape: ');
disp(size(imdb.test_labels));
</code></pre><h4 id="section-4:-call-*knn_train*-to-create-a-knn-classifier-model"><a name="section-4:-call-*knn_train*-to-create-a-knn-classifier-model" href="#section-4:-call-*knn_train*-to-create-a-knn-classifier-model"></a>section 4: Call <em>knn_train</em> to create a knn classifier model</h4><pre><code data-origin="<pre><code>% Remember that training a kNN classifier is a noop: 
% the Classifier simply remembers the data and does no further processing 
model = knn_train(imdb.train_data, imdb.train_labels);
</code></pre>">% Remember that training a kNN classifier is a noop: 
% the Classifier simply remembers the data and does no further processing 
model = knn_train(imdb.train_data, imdb.train_labels);
</code></pre><p>We would now like to classify the test data with the kNN classifier. Recall that we can break down this process into two steps:</p><ol>
<li>First we must compute the distances between all test examples and all train examples.</li><li>Given these distances, for each test example we find the k nearest examples and have them vote for the label.</li></ol><p>Lets begin with computing the distance matrix between all training and test examples. For example, if there are Ntr training examples and Nte test examples, this stage should result in a Nte x Ntr matrix where each element (i,j) is the distance between the i-th test and j-th train example.</p><p>First, open  <em>classifier/knn/knn_compute_distances_two_loops.m</em> that uses a (very inefficient) double loop over all pairs of (test, train) examples and computes the distance matrix one element at a time.</p><h4 id="section-5:-todo:-open-*classifier/knn/knn_compute_distances_two_loops.m*-and-implement-it"><a name="section-5:-todo:-open-*classifier/knn/knn_compute_distances_two_loops.m*-and-implement-it" href="#section-5:-todo:-open-*classifier/knn/knn_compute_distances_two_loops.m*-and-implement-it"></a>section 5: Todo: open <em>classifier/knn/knn_compute_distances_two_loops.m</em> and implement it</h4><pre><code data-origin="<pre><code>%Test your implementation:
dists_two = knn_compute_distances_two_loops(model, imdb.test_data);
disp(size(dists_two))
</code></pre>">%Test your implementation:
dists_two = knn_compute_distances_two_loops(model, imdb.test_data);
disp(size(dists_two))
</code></pre><p><strong>The expected results</strong>: 500 5000</p><h4 id="section-6:-todo:-now-implement-the-function-*knn_predict_labels.m*-and-run-the-code-below:"><a name="section-6:-todo:-now-implement-the-function-*knn_predict_labels.m*-and-run-the-code-below:" href="#section-6:-todo:-now-implement-the-function-*knn_predict_labels.m*-and-run-the-code-below:"></a>section 6: Todo: now implement the function <em>knn_predict_labels.m</em> and run the code below:</h4><pre><code data-origin="<pre><code>% We use k = 1 (which is Nearest Neighbor).
k = 1;
test_labels_pred = knn_predict_labels(model, dists_two, k);
num_correct = sum(sum(test_labels_pred == imdb.test_labels));
num_test = length(imdb.test_labels);
accuracy = double(num_correct)/num_test;
fprintf('Got %d / %d correct =&amp;gt; accuracy: %f\n',num_correct, num_test, accuracy);
fprintf('You should expect to see approximately 27%% accuracy\n');
</code></pre>">% We use k = 1 (which is Nearest Neighbor).
k = 1;
test_labels_pred = knn_predict_labels(model, dists_two, k);
num_correct = sum(sum(test_labels_pred == imdb.test_labels));
num_test = length(imdb.test_labels);
accuracy = double(num_correct)/num_test;
fprintf('Got %d / %d correct =&gt; accuracy: %f\n',num_correct, num_test, accuracy);
fprintf('You should expect to see approximately 27%% accuracy\n');
</code></pre><p><strong>The expected results</strong>:<br>Got 137 / 500 correct =&gt; accuracy: 0.274000<br>You should expect to see approximately 27% accuracy.</p><h4 id="section-7:-now-lets-try-out-a-larger-k,-say-k-=-5:"><a name="section-7:-now-lets-try-out-a-larger-k,-say-k-=-5:" href="#section-7:-now-lets-try-out-a-larger-k,-say-k-=-5:"></a>section 7: Now lets try out a larger k, say k = 5:</h4><pre><code data-origin="<pre><code>k = 5;
test_labels_pred = knn_predict_labels(model, dists_two, k);
num_correct = sum(sum(test_labels_pred == imdb.test_labels));
num_test = length(imdb.test_labels);
accuracy = double(num_correct)/num_test;
fprintf('Got %d / %d correct =&amp;gt; accuracy: %f\n',num_correct, num_test, accuracy);
fprintf('You should expect to see a slightly better performance than with k = 1.\n');
</code></pre>">k = 5;
test_labels_pred = knn_predict_labels(model, dists_two, k);
num_correct = sum(sum(test_labels_pred == imdb.test_labels));
num_test = length(imdb.test_labels);
accuracy = double(num_correct)/num_test;
fprintf('Got %d / %d correct =&gt; accuracy: %f\n',num_correct, num_test, accuracy);
fprintf('You should expect to see a slightly better performance than with k = 1.\n');
</code></pre><p><strong>The expected results</strong>:<br>Got 139 / 500 correct =&gt; accuracy: 0.278000<br>You should expect to see a slightly better performance than with k = 1.</p><h4 id="section-8:-now-lets-speed-up-distance-matrix-computation-by-using-partial-vectorization-with-one-loop.-implement-the-function-*knn_compute_distances_one_loop.m*-and-run-the-code-below:"><a name="section-8:-now-lets-speed-up-distance-matrix-computation-by-using-partial-vectorization-with-one-loop.-implement-the-function-*knn_compute_distances_one_loop.m*-and-run-the-code-below:" href="#section-8:-now-lets-speed-up-distance-matrix-computation-by-using-partial-vectorization-with-one-loop.-implement-the-function-*knn_compute_distances_one_loop.m*-and-run-the-code-below:"></a>section 8: Now lets speed up distance matrix computation by using partial vectorization with one loop. Implement the function <em>knn_compute_distances_one_loop.m</em> and run the code below:</h4><pre><code data-origin="<pre><code>dists_one = knn_compute_distances_one_loops(model, imdb.test_data);

% To ensure that our vectorized implementation is correct, we make sure that it
% agrees with the naive implementation. There are many ways to decide whether
% two matrices are similar; one of the simplest is the Frobenius norm. In case
% you haven't seen it before, the Frobenius norm of two matrices is the square
% root of the squared sum of differences of all elements; in other words, reshape
% the matrices into vectors and compute the Euclidean distance between them.

difference = norm(dists_two - dists_one, 'fro');
fprintf('Difference was: %f\n', difference);
if difference &amp;lt; 0.001
fprintf( 'Good! The distance matrices are the same\n');
else
fprintf( 'Uh-oh! The distance matrices are different\n');
end
</code></pre>">dists_one = knn_compute_distances_one_loops(model, imdb.test_data);

% To ensure that our vectorized implementation is correct, we make sure that it
% agrees with the naive implementation. There are many ways to decide whether
% two matrices are similar; one of the simplest is the Frobenius norm. In case
% you haven't seen it before, the Frobenius norm of two matrices is the square
% root of the squared sum of differences of all elements; in other words, reshape
% the matrices into vectors and compute the Euclidean distance between them.

difference = norm(dists_two - dists_one, 'fro');
fprintf('Difference was: %f\n', difference);
if difference &lt; 0.001
fprintf( 'Good! The distance matrices are the same\n');
else
fprintf( 'Uh-oh! The distance matrices are different\n');
end
</code></pre><p><strong>The expected results</strong>:<br>Difference was: 0.000000<br>Good! The distance matrices are the same</p><h4 id="section-9:-now-implement-the-fully-vectorized-version-inside-*knn_compute_distances_no_loops.m*-and-run-the-code"><a name="section-9:-now-implement-the-fully-vectorized-version-inside-*knn_compute_distances_no_loops.m*-and-run-the-code" href="#section-9:-now-implement-the-fully-vectorized-version-inside-*knn_compute_distances_no_loops.m*-and-run-the-code"></a>section 9: Now implement the fully vectorized version inside <em>knn_compute_distances_no_loops.m</em> and run the code</h4><pre><code data-origin="<pre><code>dists_no = knn_compute_distances_no_loops(model, imdb.test_data);

%check that the distance matrix agrees with the one we computed before:
difference = norm(dists_two - dists_no, 'fro');
fprintf('Difference was: %f\n', difference);
if difference &amp;lt; 0.001
fprintf( 'Good! The distance matrices are the same\n');
else
fprintf( 'Uh-oh! The distance matrices are different\n');
end
</code></pre>">dists_no = knn_compute_distances_no_loops(model, imdb.test_data);

%check that the distance matrix agrees with the one we computed before:
difference = norm(dists_two - dists_no, 'fro');
fprintf('Difference was: %f\n', difference);
if difference &lt; 0.001
fprintf( 'Good! The distance matrices are the same\n');
else
fprintf( 'Uh-oh! The distance matrices are different\n');
end
</code></pre><p><strong>The expected results</strong>:<br>Difference was: 0.000000<br>Good! The distance matrices are the same</p><h4 id="section-10:-let's-compare-how-fast-the-implementations-are"><a name="section-10:-let's-compare-how-fast-the-implementations-are" href="#section-10:-let's-compare-how-fast-the-implementations-are"></a>section 10: Let’s compare how fast the implementations are</h4><pre><code data-origin="<pre><code>tic;
knn_compute_distances_two_loops(model, imdb.test_data);
two_loop_time = toc;
fprintf('Two loop version took %f seconds\n',two_loop_time);

tic;
knn_compute_distances_one_loops(model, imdb.test_data);
two_loop_time = toc;
fprintf('One loop version took %f seconds\n',two_loop_time);

tic;
knn_compute_distances_no_loops(model, imdb.test_data);
two_loop_time = toc;
fprintf('No loop version took %f seconds\n',two_loop_time);
fprintf('you should see significantly faster performance with the fully vectorized implementation\n');
</code></pre>">tic;
knn_compute_distances_two_loops(model, imdb.test_data);
two_loop_time = toc;
fprintf('Two loop version took %f seconds\n',two_loop_time);

tic;
knn_compute_distances_one_loops(model, imdb.test_data);
two_loop_time = toc;
fprintf('One loop version took %f seconds\n',two_loop_time);

tic;
knn_compute_distances_no_loops(model, imdb.test_data);
two_loop_time = toc;
fprintf('No loop version took %f seconds\n',two_loop_time);
fprintf('you should see significantly faster performance with the fully vectorized implementation\n');
</code></pre><p><strong>The expected results</strong>:<br>Two loop version took 65.902485 seconds<br>One loop version took 23.783070 seconds<br>No loop version took 0.353753 seconds<br>you should see significantly faster performance with the fully vectorized implementation</p><h4 id="section-11:-cross-validation"><a name="section-11:-cross-validation" href="#section-11:-cross-validation"></a>section 11: Cross-validation</h4><p>We have implemented the k-Nearest Neighbor classifier but we set the value k = 5 arbitrarily. We will now determine the best value of this hyperparameter with cross-validation.</p><pre><code data-origin="<pre><code>num_folds = 5;
k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100];
X_train_folds = {};
y_train_folds = {};

% ################################################################################
% # TODO:                                                                        #
% # Split up the training data into folds. After splitting, X_train_folds and    #
% # y_train_folds should each be lists of length num_folds, where                #
% # y_train_folds[i] is the label vector for the points in X_train_folds[i].     #
% # Hint: Look up the mat2cell function.                                #
% ################################################################################

**your code**

% ################################################################################
% #                                 END OF YOUR CODE                             #
% ################################################################################
% 
% # A dictionary holding the accuracies for different values of k that we find
% # when running cross-validation. After running cross-validation,
% # k_to_accuracies[k] should be a list of length num_folds giving the different
% # accuracy values that we found when using that value of k.

k_to_accuracies = {};

% ################################################################################
% # TODO:                                                                        #
% # Perform k-fold cross validation to find the best value of k. For each        #
% # possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #
% # where in each case you use all but one of the folds as training data and the #
% # last fold as a validation set. Store the accuracies for all fold and all     #
% # values of k in the k_to_accuracies dictionary.                               #
% ################################################################################

**your code** 

% ################################################################################
% #                                 END OF YOUR CODE                             #
% ################################################################################

%  Print out the computed accuracies
for k = 1:size(k_to_accuracies,1)
    for i = 1:size(k_to_accuracies, 2)
        fprintf('k = %d, accuracy = %f\n',k_choices(k), k_to_accuracies(k, i));
    end
end
</code></pre>">num_folds = 5;
k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100];
X_train_folds = {};
y_train_folds = {};

% ################################################################################
% # TODO:                                                                        #
% # Split up the training data into folds. After splitting, X_train_folds and    #
% # y_train_folds should each be lists of length num_folds, where                #
% # y_train_folds[i] is the label vector for the points in X_train_folds[i].     #
% # Hint: Look up the mat2cell function.                                #
% ################################################################################

**your code**

% ################################################################################
% #                                 END OF YOUR CODE                             #
% ################################################################################
% 
% # A dictionary holding the accuracies for different values of k that we find
% # when running cross-validation. After running cross-validation,
% # k_to_accuracies[k] should be a list of length num_folds giving the different
% # accuracy values that we found when using that value of k.

k_to_accuracies = {};

% ################################################################################
% # TODO:                                                                        #
% # Perform k-fold cross validation to find the best value of k. For each        #
% # possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #
% # where in each case you use all but one of the folds as training data and the #
% # last fold as a validation set. Store the accuracies for all fold and all     #
% # values of k in the k_to_accuracies dictionary.                               #
% ################################################################################

**your code** 

% ################################################################################
% #                                 END OF YOUR CODE                             #
% ################################################################################

%  Print out the computed accuracies
for k = 1:size(k_to_accuracies,1)
    for i = 1:size(k_to_accuracies, 2)
        fprintf('k = %d, accuracy = %f\n',k_choices(k), k_to_accuracies(k, i));
    end
end
</code></pre><p><strong>The expected results</strong>:<br>k = 1, accuracy = 0.263000<br>k = 1, accuracy = 0.257000<br>k = 1, accuracy = 0.264000<br>k = 1, accuracy = 0.278000<br>k = 1, accuracy = 0.266000<br>k = 3, accuracy = 0.239000<br>k = 3, accuracy = 0.249000<br>k = 3, accuracy = 0.240000<br>k = 3, accuracy = 0.266000<br>k = 3, accuracy = 0.254000<br>k = 5, accuracy = 0.248000<br>k = 5, accuracy = 0.266000<br>k = 5, accuracy = 0.280000<br>k = 5, accuracy = 0.292000<br>k = 5, accuracy = 0.280000<br>k = 8, accuracy = 0.262000<br>k = 8, accuracy = 0.282000<br>k = 8, accuracy = 0.273000<br>k = 8, accuracy = 0.290000<br>k = 8, accuracy = 0.273000<br>k = 10, accuracy = 0.265000<br>k = 10, accuracy = 0.296000<br>k = 10, accuracy = 0.276000<br>k = 10, accuracy = 0.284000<br>k = 10, accuracy = 0.280000<br>k = 12, accuracy = 0.260000<br>k = 12, accuracy = 0.295000<br>k = 12, accuracy = 0.279000<br>k = 12, accuracy = 0.283000<br>k = 12, accuracy = 0.280000<br>k = 15, accuracy = 0.252000<br>k = 15, accuracy = 0.289000<br>k = 15, accuracy = 0.278000<br>k = 15, accuracy = 0.282000<br>k = 15, accuracy = 0.274000<br>k = 20, accuracy = 0.270000<br>k = 20, accuracy = 0.279000<br>k = 20, accuracy = 0.279000<br>k = 20, accuracy = 0.282000<br>k = 20, accuracy = 0.285000<br>k = 50, accuracy = 0.271000<br>k = 50, accuracy = 0.288000<br>k = 50, accuracy = 0.278000<br>k = 50, accuracy = 0.269000<br>k = 50, accuracy = 0.266000<br>k = 100, accuracy = 0.256000<br>k = 100, accuracy = 0.270000<br>k = 100, accuracy = 0.263000<br>k = 100, accuracy = 0.256000<br>k = 100, accuracy = 0.263000</p><pre><code data-origin="<pre><code>% # plot the raw observations
figure;
hold on;
for k = 1:length(k_choices)
    scatter(ones(1, size(k_to_accuracies,2))*k_choices(k), k_to_accuracies(k,:))
end
accuaracies_mean = mean(k_to_accuracies,2);
accuaracies_std  = std(k_to_accuracies,0,2);
errorbar(k_choices, accuaracies_mean, accuaracies_std);
title('Cross-validation on k')
xlabel('k')
ylabel('Cross-validation accuracy')
hold off;
</code></pre>">% # plot the raw observations
figure;
hold on;
for k = 1:length(k_choices)
    scatter(ones(1, size(k_to_accuracies,2))*k_choices(k), k_to_accuracies(k,:))
end
accuaracies_mean = mean(k_to_accuracies,2);
accuaracies_std  = std(k_to_accuracies,0,2);
errorbar(k_choices, accuaracies_mean, accuaracies_std);
title('Cross-validation on k')
xlabel('k')
ylabel('Cross-validation accuracy')
hold off;
</code></pre><p><strong>The expected results</strong>:<br><img src="https://raw.githubusercontent.com/MatthiasDING/BE_1/master/Document/knn_cross.jpg" alt=""></p><pre><code data-origin="<pre><code>% # Based on the cross-validation results above, choose the best value for k,   
% # retrain the classifier using all the training data, and test it on the test
% # data.
best_k = 6;
model = knn_train(imdb.train_data, imdb.train_labels);
labels_pred = knn_predict(model, imdb.test_data, best_k);
num_correct = sum(sum(labels_pred == imdb.test_labels));
num_test = length(imdb.test_labels);
accuracy = double(num_correct)/num_test;
fprintf('Got %d / %d correct =&amp;gt; accuracy: %f\n',num_correct, num_test, accuracy);
</code></pre>">% # Based on the cross-validation results above, choose the best value for k,   
% # retrain the classifier using all the training data, and test it on the test
% # data.
best_k = 6;
model = knn_train(imdb.train_data, imdb.train_labels);
labels_pred = knn_predict(model, imdb.test_data, best_k);
num_correct = sum(sum(labels_pred == imdb.test_labels));
num_test = length(imdb.test_labels);
accuracy = double(num_correct)/num_test;
fprintf('Got %d / %d correct =&gt; accuracy: %f\n',num_correct, num_test, accuracy);
</code></pre><p><strong>The expected results</strong>:<br>Got 141 / 500 correct =&gt; accuracy: 0.282000</p>

<footer style="position:fixed; font-size:.8em; text-align:right; bottom:0px; margin-left:-25px; height:20px; width:100%;">generated by <a href="http://pad.haroopress.com" target="_blank">haroopad</a></footer>
</body>
</html>
